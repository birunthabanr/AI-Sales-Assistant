{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ab6a8ae",
   "metadata": {},
   "source": [
    "<!-- ## Imports -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9003ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b40ef4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 896 examples from Services & Events domains.\n",
      "{\n",
      "  \"text\": \"I'm looking for events in NY, and heard the Yankees vs orioles is fun.\",\n",
      "  \"intent\": \"GetEventDates\",\n",
      "  \"slots\": {\n",
      "    \"city\": \"NY\",\n",
      "    \"event_name\": \"Yankees vs orioles\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"text\": \"Great.\",\n",
      "  \"intent\": \"GetEventDates\",\n",
      "  \"slots\": {\n",
      "    \"city\": \"NY\",\n",
      "    \"date\": \"today\",\n",
      "    \"event_name\": \"Yankees vs Orioles\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"text\": \"Yes, one ticket please.\",\n",
      "  \"intent\": \"BuyEventTickets\",\n",
      "  \"slots\": {\n",
      "    \"city\": \"NY\",\n",
      "    \"date\": \"today\",\n",
      "    \"event_name\": \"Yankees vs Orioles\",\n",
      "    \"number_of_tickets\": \"1\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 1. Load the DSTC8 dialogues JSON file\n",
    "with open('../../data/train/dialogues_004.json', 'r', encoding='utf-8') as f:\n",
    "    dialogues = json.load(f)\n",
    "\n",
    "# 2. Define target domains & intents for Services and Events\n",
    "target_domains = ['Services_1', 'Services_2', 'Services_3', 'Events_1', 'Events_2']\n",
    "target_intents = {\n",
    "    'Services': ['BookAppointment', 'FindProvider'],\n",
    "    'Events': ['FindEvents', 'BuyEventTickets', 'GetEventDates']\n",
    "}\n",
    "\n",
    "# 3. Prepare list to hold extracted examples\n",
    "examples = []\n",
    "\n",
    "for dialogue in dialogues:\n",
    "    # Filter dialogues to only those with at least one target domain\n",
    "    if not any(domain in dialogue['services'] for domain in target_domains):\n",
    "        continue  # Skip dialogues outside our target domains\n",
    "    \n",
    "    for turn in dialogue['turns']:\n",
    "        # Each turn can have multiple frames (one per service)\n",
    "        frames = turn.get('frames', [])\n",
    "        for frame in frames:\n",
    "            service = frame.get('service')\n",
    "            # Skip if service not in target domains\n",
    "            if service not in target_domains:\n",
    "                continue\n",
    "            \n",
    "            # Get dialog state info\n",
    "            state = frame.get('state', {})\n",
    "            intent = state.get('active_intent')\n",
    "            if not intent:\n",
    "                continue\n",
    "            \n",
    "            # Check if intent is in our target intents for this domain\n",
    "            domain_key = 'Services' if 'Services' in service else 'Events'\n",
    "            if intent not in target_intents[domain_key]:\n",
    "                continue\n",
    "            \n",
    "            # Extract utterance text from the turn\n",
    "            utterance = turn.get('utterance', '').strip()\n",
    "            if not utterance:\n",
    "                continue\n",
    "            \n",
    "            # Extract slot values from state.slot_values\n",
    "            # slot_values is a dict with keys = slot names, values = list of strings\n",
    "            slot_values = state.get('slot_values', {})\n",
    "            # Convert slot values from list to single string (if exists)\n",
    "            slots = {k: v[0] if isinstance(v, list) and len(v) > 0 else '' for k, v in slot_values.items()}\n",
    "            \n",
    "            # Store example\n",
    "            examples.append({\n",
    "                \"text\": utterance,\n",
    "                \"intent\": intent,\n",
    "                \"slots\": slots\n",
    "            })\n",
    "\n",
    "print(f\"Extracted {len(examples)} examples from Services & Events domains.\")\n",
    "\n",
    "# Optional: view first 3 examples\n",
    "for example in examples[:3]:\n",
    "    print(json.dumps(example, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03231b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Banks_1 (2 intents) ===\n",
      "- CheckBalance\n",
      "- TransferMoney\n",
      "\n",
      "=== Buses_1 (2 intents) ===\n",
      "- FindBus\n",
      "- BuyBusTicket\n",
      "\n",
      "=== Buses_2 (2 intents) ===\n",
      "- FindBus\n",
      "- BuyBusTicket\n",
      "\n",
      "=== Calendar_1 (3 intents) ===\n",
      "- GetEvents\n",
      "- GetAvailableTime\n",
      "- AddEvent\n",
      "\n",
      "=== Events_1 (2 intents) ===\n",
      "- FindEvents\n",
      "- BuyEventTickets\n",
      "\n",
      "=== Events_2 (3 intents) ===\n",
      "- FindEvents\n",
      "- GetEventDates\n",
      "- BuyEventTickets\n",
      "\n",
      "=== Flights_1 (4 intents) ===\n",
      "- SearchOnewayFlight\n",
      "- SearchRoundtripFlights\n",
      "- ReserveOnewayFlight\n",
      "- ReserveRoundtripFlights\n",
      "\n",
      "=== Flights_2 (2 intents) ===\n",
      "- SearchOnewayFlight\n",
      "- SearchRoundtripFlights\n",
      "\n",
      "=== Homes_1 (2 intents) ===\n",
      "- FindApartment\n",
      "- ScheduleVisit\n",
      "\n",
      "=== Hotels_1 (2 intents) ===\n",
      "- ReserveHotel\n",
      "- SearchHotel\n",
      "\n",
      "=== Hotels_2 (2 intents) ===\n",
      "- BookHouse\n",
      "- SearchHouse\n",
      "\n",
      "=== Hotels_3 (2 intents) ===\n",
      "- ReserveHotel\n",
      "- SearchHotel\n",
      "\n",
      "=== Media_1 (2 intents) ===\n",
      "- FindMovies\n",
      "- PlayMovie\n",
      "\n",
      "=== Movies_1 (3 intents) ===\n",
      "- BuyMovieTickets\n",
      "- FindMovies\n",
      "- GetTimesForMovie\n",
      "\n",
      "=== Music_1 (2 intents) ===\n",
      "- LookupSong\n",
      "- PlaySong\n",
      "\n",
      "=== Music_2 (2 intents) ===\n",
      "- LookupMusic\n",
      "- PlayMedia\n",
      "\n",
      "=== RentalCars_1 (2 intents) ===\n",
      "- GetCarsAvailable\n",
      "- ReserveCar\n",
      "\n",
      "=== RentalCars_2 (2 intents) ===\n",
      "- GetCarsAvailable\n",
      "- ReserveCar\n",
      "\n",
      "=== Restaurants_1 (2 intents) ===\n",
      "- ReserveRestaurant\n",
      "- FindRestaurants\n",
      "\n",
      "=== RideSharing_1 (1 intents) ===\n",
      "- GetRide\n",
      "\n",
      "=== RideSharing_2 (1 intents) ===\n",
      "- GetRide\n",
      "\n",
      "=== Services_1 (2 intents) ===\n",
      "- BookAppointment\n",
      "- FindProvider\n",
      "\n",
      "=== Services_2 (2 intents) ===\n",
      "- BookAppointment\n",
      "- FindProvider\n",
      "\n",
      "=== Services_3 (2 intents) ===\n",
      "- BookAppointment\n",
      "- FindProvider\n",
      "\n",
      "=== Travel_1 (1 intents) ===\n",
      "- FindAttractions\n",
      "\n",
      "=== Weather_1 (1 intents) ===\n",
      "- GetWeather\n",
      "\n",
      "Total unique intents across all services: 37\n"
     ]
    }
   ],
   "source": [
    "# Load the schema file\n",
    "with open('../../data/train/schema.json', 'r', encoding='utf-8') as f:\n",
    "    schema = json.load(f)\n",
    "\n",
    "# Set to store unique intent names\n",
    "unique_intents = set()\n",
    "\n",
    "# Process and print intents per service\n",
    "for service in schema:\n",
    "    service_name = service['service_name']\n",
    "    intents = service.get('intents', [])\n",
    "    \n",
    "    print(f'\\n=== {service_name} ({len(intents)} intents) ===')\n",
    "    for intent in intents:\n",
    "        intent_name = intent['name']\n",
    "        unique_intents.add(intent_name)\n",
    "        print(f\"- {intent_name}\")\n",
    "\n",
    "# Print total number of unique intents\n",
    "print(f'\\nTotal unique intents across all services: {len(unique_intents)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50437d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Filtered 5398 dialogues saved to: ../../data/filtered_dialogues.json\n"
     ]
    }
   ],
   "source": [
    "# Define the target domains/services\n",
    "target_domains = {'Services_1', 'Services_2', 'Services_3', 'Events_1', 'Events_2'}\n",
    "\n",
    "# Directory path where your DSTC8 training data is stored\n",
    "data_dir = '../../data/train'\n",
    "output_path = '../../data/filtered_dialogues.json'\n",
    "\n",
    "# Function to check if a dialogue is in the target domains\n",
    "def dialogue_in_target_domains(dialogue, target_domains):\n",
    "    return any(service in target_domains for service in dialogue['services'])\n",
    "\n",
    "# Get all files matching pattern dialogues_*.json\n",
    "dialogue_files = [f for f in os.listdir(data_dir) if f.startswith('dialogues_') and f.endswith('.json')]\n",
    "\n",
    "filtered_dialogues = []\n",
    "\n",
    "# Process each dialogue file\n",
    "for file in dialogue_files:\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        dialogues = json.load(f)\n",
    "        for dialogue in dialogues:\n",
    "            if dialogue_in_target_domains(dialogue, target_domains):\n",
    "                filtered_dialogues.append(dialogue)\n",
    "\n",
    "# Save the filtered dialogues to a new JSON file\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(filtered_dialogues, f, indent=2)\n",
    "\n",
    "print(f\"✅ Filtered {len(filtered_dialogues)} dialogues saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "392026e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total extracted examples: 39081\n",
      "[(\"Ok, It's fine. I would like to do something interesting\", 'FindEvents'), (\"I'd like a Concert\", 'FindEvents'), ('Where is the place?', 'FindEvents'), ('What kind of concert is it? What time does it start?', 'FindEvents'), ('Ok, thanks for these information.', 'FindEvents')]\n"
     ]
    }
   ],
   "source": [
    "with open('../../data/filtered_dialogues.json', 'r', encoding='utf-8') as f:\n",
    "    filtered_dialogues = json.load(f)\n",
    "\n",
    "target_domains = {'Services_1', 'Services_2', 'Services_3', 'Events_1', 'Events_2'}\n",
    "examples = []\n",
    "\n",
    "for dialogue in filtered_dialogues:\n",
    "    for turn in dialogue['turns']:\n",
    "        if turn['speaker'] == 'USER' and turn['frames']:\n",
    "            for frame in turn['frames']:\n",
    "                # Keep only the turns for your selected services/domains\n",
    "                if frame.get('service') in target_domains:\n",
    "                    intent = frame.get('state', {}).get('active_intent')\n",
    "                    utterance = turn.get('utterance')\n",
    "                    if intent and utterance:\n",
    "                        examples.append((utterance, intent))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Total extracted examples: {len(examples)}\")\n",
    "\n",
    "print(examples[:5])  # Print first 5 examples for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab6ecb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0: type=<class 'tuple'>, value=(\"Ok, It's fine. I would like to do something interesting\", 'FindEvents')\n",
      "Example 1: type=<class 'tuple'>, value=(\"I'd like a Concert\", 'FindEvents')\n",
      "Example 2: type=<class 'tuple'>, value=('Where is the place?', 'FindEvents')\n",
      "Example 3: type=<class 'tuple'>, value=('What kind of concert is it? What time does it start?', 'FindEvents')\n",
      "Example 4: type=<class 'tuple'>, value=('Ok, thanks for these information.', 'FindEvents')\n",
      "Example 5: type=<class 'tuple'>, value=('Not now, thanks. I need a house to stay there, a house with rating 4.1 or higher, for 1 people, with laundry service.', 'NONE')\n",
      "Example 6: type=<class 'tuple'>, value=(\"That sounds great. I'd also like to catch a pop event while I'm there, preferably on the 2nd.\", 'FindEvents')\n",
      "Example 7: type=<class 'tuple'>, value=('A concert would be music to my ears.', 'FindEvents')\n",
      "Example 8: type=<class 'tuple'>, value=('Can you find me something with an international flavor?', 'FindEvents')\n",
      "Example 9: type=<class 'tuple'>, value=(\"That sounds appealing. So now I need to find a house to stay in while I'm there, something with a 4.4 rating or higher.\", 'FindEvents')\n"
     ]
    }
   ],
   "source": [
    "for i, example in enumerate(examples[:10]):\n",
    "    print(f\"Example {i}: type={type(example)}, value={example}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed721cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned examples count: 39081\n"
     ]
    }
   ],
   "source": [
    "cleaned_examples = [ex for ex in examples if isinstance(ex, (list, tuple)) and len(ex) == 2]\n",
    "print(f\"Cleaned examples count: {len(cleaned_examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ba1c8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ok, It's fine. I would like to do something in...</td>\n",
       "      <td>FindEvents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'd like a Concert</td>\n",
       "      <td>FindEvents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Where is the place?</td>\n",
       "      <td>FindEvents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What kind of concert is it? What time does it ...</td>\n",
       "      <td>FindEvents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ok, thanks for these information.</td>\n",
       "      <td>FindEvents</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Utterance      Intent\n",
       "0  Ok, It's fine. I would like to do something in...  FindEvents\n",
       "1                                 I'd like a Concert  FindEvents\n",
       "2                                Where is the place?  FindEvents\n",
       "3  What kind of concert is it? What time does it ...  FindEvents\n",
       "4                  Ok, thanks for these information.  FindEvents"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(cleaned_examples, columns=['Utterance', 'Intent'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "951401d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 31264, Validation: 3908, Test: 3909\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "print(f\"Train: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19a6d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = sorted(df['Intent'].unique())\n",
    "intent2id = {intent: i for i, intent in enumerate(intents)}\n",
    "id2intent = {i: intent for intent, i in intent2id.items()}\n",
    "\n",
    "train_df['IntentID'] = train_df['Intent'].map(intent2id)\n",
    "val_df['IntentID'] = val_df['Intent'].map(intent2id)\n",
    "test_df['IntentID'] = test_df['Intent'].map(intent2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b5421ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Utterance</th>\n",
       "      <th>Intent</th>\n",
       "      <th>IntentID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7725</th>\n",
       "      <td>That sounds great for me.</td>\n",
       "      <td>FindEvents</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23427</th>\n",
       "      <td>Hi, i need a help, i am looking or a doctor in...</td>\n",
       "      <td>FindProvider</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26153</th>\n",
       "      <td>What's the address?</td>\n",
       "      <td>FindEvents</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21299</th>\n",
       "      <td>Great, when am I free on that day?</td>\n",
       "      <td>FindProvider</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10031</th>\n",
       "      <td>Are there any other events?</td>\n",
       "      <td>FindEvents</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Utterance        Intent  \\\n",
       "7725                           That sounds great for me.    FindEvents   \n",
       "23427  Hi, i need a help, i am looking or a doctor in...  FindProvider   \n",
       "26153                                What's the address?    FindEvents   \n",
       "21299                 Great, when am I free on that day?  FindProvider   \n",
       "10031                        Are there any other events?    FindEvents   \n",
       "\n",
       "       IntentID  \n",
       "7725          2  \n",
       "23427         3  \n",
       "26153         2  \n",
       "21299         3  \n",
       "10031         2  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d83b4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FindEvents', 'FindProvider', 'BookAppointment', 'BuyEventTickets',\n",
       "       'NONE', 'GetEventDates'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Intent'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d221abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch['Utterance'].tolist(), \n",
    "        padding='max_length', \n",
    "        truncation=True,\n",
    "        max_length=32  # adjust as needed\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize_batch(train_df)\n",
    "val_encodings = tokenize_batch(val_df)\n",
    "test_encodings = tokenize_batch(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04a56ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def build_hf_dataset(encodings, labels):\n",
    "    # Build dictionary for HuggingFace Dataset\n",
    "    encodings.update({'labels': labels})\n",
    "    return Dataset.from_dict(encodings)\n",
    "\n",
    "# Convert your intent labels (e.g., train_df['Label']) to list or numpy array\n",
    "train_dataset = build_hf_dataset(train_encodings, train_df['Intent'].tolist())\n",
    "val_dataset = build_hf_dataset(val_encodings, val_df['Intent'].tolist())\n",
    "test_dataset = build_hf_dataset(test_encodings, test_df['Intent'].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33817d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent2id = {intent: idx for idx, intent in enumerate(sorted(df['Intent'].unique()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3377e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your original label column still contains strings in train_df/val_df\n",
    "train_labels = train_df['Intent'].map(intent2id).tolist()\n",
    "val_labels = val_df['Intent'].map(intent2id).tolist()\n",
    "test_labels = test_df['Intent'].map(intent2id).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "218ea2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = {\n",
    "    'input_ids': train_encodings['input_ids'],\n",
    "    'attention_mask': train_encodings['attention_mask'],\n",
    "    'labels': train_labels  # <-- Now integer IDs!\n",
    "}\n",
    "val_inputs = {\n",
    "    'input_ids': val_encodings['input_ids'],\n",
    "    'attention_mask': val_encodings['attention_mask'],\n",
    "    'labels': val_labels\n",
    "}\n",
    "\n",
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_dict(train_inputs)\n",
    "val_dataset = Dataset.from_dict(val_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b51128a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 3531, 2191, 2033, 2019, 6098, 2000, 1996, 24385, 2006, 2008, 2154, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 0}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9cb00e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/anaconda3/envs/tfenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5862' max='5862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5862/5862 11:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.505400</td>\n",
       "      <td>0.471350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.429900</td>\n",
       "      <td>0.450270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.374200</td>\n",
       "      <td>0.455806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tfenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/envs/tfenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/envs/tfenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5862, training_loss=0.46011358786263756, metrics={'train_runtime': 694.5545, 'train_samples_per_second': 135.039, 'train_steps_per_second': 8.44, 'total_flos': 1542412399325184.0, 'train_loss': 0.46011358786263756, 'epoch': 3.0})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=len(intent2id)  # intent2id maps label strings to integers\n",
    ")\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy='epoch',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1260fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     'bert-base-uncased', \n",
    "#     num_labels=len(intent2id)\n",
    "# )\n",
    "# args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     evaluation_strategy='epoch',\n",
    "#     num_train_epochs=3,\n",
    "#     per_device_train_batch_size=16,\n",
    "#     per_device_eval_batch_size=16,\n",
    "#     learning_rate=2e-5,\n",
    "# )\n",
    "\n",
    "# # You would need a Dataset class or Hugging Face Datasets integration for this\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=args,\n",
    "#     train_dataset=train_df,\n",
    "#     eval_dataset=val_df,\n",
    "# )\n",
    "\n",
    "# trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "898ff532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 3531, 2191, 2033, 2019, 6098, 2000, 1996, 24385, 2006, 2008, 2154, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': 'BookAppointment'}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "439972f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [245/245 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_runtime': 6.625, 'eval_samples_per_second': 590.037, 'eval_steps_per_second': 36.981, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate(test_dataset)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ffda15f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='weighted')\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1c8b76a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,        # your TrainingArguments\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,  # or test_dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cc81c307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.455806165933609, 'eval_model_preparation_time': 0.0017, 'eval_accuracy': 0.8142272262026612, 'eval_precision': 0.8135234245118433, 'eval_recall': 0.8142272262026612, 'eval_f1': 0.8129443898121915, 'eval_runtime': 7.1101, 'eval_samples_per_second': 549.64, 'eval_steps_per_second': 34.458}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b704bc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tfenv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(val_dataset)\n",
    "y_pred = predictions.predictions.argmax(axis=-1)\n",
    "y_true = predictions.label_ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
